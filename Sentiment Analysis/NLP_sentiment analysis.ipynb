{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sentiment Analysis</h3>\n",
    "\n",
    "We are going to use a dataset from <b>IMDB</b> movie review. \n",
    "\n",
    "Let's start by importing the necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras.preprocessing import sequence\n",
    "#import keras.engine.topology as KE\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "VOCAB_SIZE = 88584\n",
    "\n",
    "MAXLEN = 250\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words = VOCAB_SIZE)\n",
    "\n",
    "#train_data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the review is greater than 250 words then trim off the extra words. \n",
    "If the review is less than 250 words add the necessary amount to make it 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sequence.pad_sequences(train_data, MAXLEN)\n",
    "test_data  = sequence.pad_sequences(test_data, MAXLEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our model. It will have a sequential architecture with one LSTM layer. 32 stands for the output dimension of the vectors generated by the embedding layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 64)          5669376   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 5,681,825\n",
      "Trainable params: 5,681,825\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(VOCAB_SIZE, 64),\n",
    "    tf.keras.layers.LSTM(32),\n",
    "    tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now train the model using train data and labels, using 10% of the data to perform testing validation.\n",
    "\n",
    "Important hyper-parameters include: \n",
    "10 epochs & a\n",
    "64 batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "704/704 [==============================] - 86s 120ms/step - loss: 0.4013 - acc: 0.8202 - val_loss: 0.3063 - val_acc: 0.8748\n",
      "Epoch 2/10\n",
      "704/704 [==============================] - 74s 104ms/step - loss: 0.2341 - acc: 0.9113 - val_loss: 0.3881 - val_acc: 0.8300\n",
      "Epoch 3/10\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.1834 - acc: 0.9327 - val_loss: 0.3550 - val_acc: 0.8676\n",
      "Epoch 4/10\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.1492 - acc: 0.9474 - val_loss: 0.3495 - val_acc: 0.8804\n",
      "Epoch 5/10\n",
      "704/704 [==============================] - 57s 81ms/step - loss: 0.1275 - acc: 0.9555 - val_loss: 0.2822 - val_acc: 0.8848\n",
      "Epoch 6/10\n",
      "704/704 [==============================] - 56s 80ms/step - loss: 0.1070 - acc: 0.9631 - val_loss: 0.3069 - val_acc: 0.8968\n",
      "Epoch 7/10\n",
      "704/704 [==============================] - 57s 82ms/step - loss: 0.0912 - acc: 0.9698 - val_loss: 0.3162 - val_acc: 0.8996\n",
      "Epoch 8/10\n",
      "704/704 [==============================] - 59s 84ms/step - loss: 0.0776 - acc: 0.9740 - val_loss: 0.4315 - val_acc: 0.8880\n",
      "Epoch 9/10\n",
      "704/704 [==============================] - 65s 92ms/step - loss: 0.0675 - acc: 0.9779 - val_loss: 0.3709 - val_acc: 0.8988\n",
      "Epoch 10/10\n",
      "704/704 [==============================] - 61s 87ms/step - loss: 0.0588 - acc: 0.9819 - val_loss: 0.4273 - val_acc: 0.8824\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"binary_crossentropy\" ,optimizer=\"rmsprop\",metrics=['acc'])\n",
    "history = model.fit(train_data, train_labels, epochs=10, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model using test data and labels. The model is 85.97% accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 19s 24ms/step - loss: 0.5147 - acc: 0.8551\n",
      "[0.5146768093109131, 0.8551200032234192]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data, test_labels)\n",
    "print(results)\n",
    "\n",
    "\n",
    "#model.save('sentiment-analysis.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language in its original form cannot be accurately processed by a machine, so you need to process the language to make it easier for the machine to understand. The first part of making sense of the data is through a process called tokenization, or splitting strings into smaller parts called tokens.\n",
    "\n",
    "A token is a sequence of characters in text that serves as a unit. Based on how you create the tokens, they may consist of words, emoticons, hashtags, links, or even individual characters. A basic way of breaking language into tokens is by splitting the text based on whitespace and punctuation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0  12  17  13  40 477  35 477]\n"
     ]
    }
   ],
   "source": [
    "import keras as ass\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "def encode_text(text):\n",
    "    tokens = ass.preprocessing.text.text_to_word_sequence(text)\n",
    "    tokens = [word_index[word] if word in word_index else 0 for word in tokens]\n",
    "    return sequence.pad_sequences([tokens], MAXLEN)[0]\n",
    "\n",
    "text = \"that movie was just amazing, so amazing\"\n",
    "encoded = encode_text(text)\n",
    "print(encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that movie was just amazing so amazing\n"
     ]
    }
   ],
   "source": [
    "reverse_word_index = {value: key for (key, value) in word_index.items()}\n",
    "\n",
    "def decode_integers(integers):\n",
    "    PAD = 0\n",
    "    text = \"\"\n",
    "    for num in integers:\n",
    "        if num != PAD:\n",
    "            text += reverse_word_index[num] + \" \"\n",
    "            \n",
    "    return text[:-1]\n",
    "\n",
    "print(decode_integers(encoded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's test the model using sample reviews.\n",
    "\n",
    "We will use a positive and negative review. The expected output for a positive review should be higher than that of a negative review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9882065]\n",
      "[0.49058613]\n"
     ]
    }
   ],
   "source": [
    "def predict(text):\n",
    "    encoded_text = encode_text(text)\n",
    "    pred = np.zeros((1,250))\n",
    "    pred[0] = encoded_text\n",
    "    result = model.predict(pred)\n",
    "    print(result[0])\n",
    "positive_review = \"It not only serves as an item of good entertainment, but is also admirable in depicting the scientific changes in the USA in the 1960s, the social life issues of that era, and differences that existed in the country, especially among African-Americans.\"\n",
    "predict(positive_review)\n",
    "\n",
    "negative_review = \"If you can keep both eyes open through its whole three-hour length you're a better man than I am.\"\n",
    "predict(negative_review)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really impressive results. You can try out testing your own reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Conclusion</h3>\n",
    "\n",
    "You can load pre-trained models and have some fun with <b>Sentiment Analysis</b>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = tf.keras.models.load_model('sentiment-analysis.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hope you had fun. Thanks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
